{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b283730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Amazon\n",
    "\n",
    "\n",
    "#### globals\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "df = pd.DataFrame(columns=['depth', \"heads\", \"epochs\", \"activation_func\", \"final_train_score\", \"valid_score\", \"test_score\"])\n",
    "\n",
    "## tuning params\n",
    "hyper_parameters = {\n",
    "    \"depth\": list(range(1,6)),\n",
    "    \"heads\": list(range(1, 9)),\n",
    "    \"epochs\": list(range(50, 600, 50)),\n",
    "    \"activation_func\": [F.elu, F.relu, F.tanh]\n",
    "}\n",
    "\n",
    "## load datset\n",
    "dataset = 'Photo'\n",
    "path = os.path.join('data', dataset)\n",
    "dataset = Amazon(path, dataset, transform=T.NormalizeFeatures())\n",
    "\n",
    "## seeds\n",
    "torch.manual_seed(0)\n",
    "\n",
    "## add train / valid / test masks\n",
    "dataset.shuffle()\n",
    "data = dataset[0]\n",
    "data.train_mask = torch.zeros([data.num_nodes,], dtype=torch.bool)\n",
    "\n",
    "print(dataset.num_classes) # 8\n",
    "# 8 * 20 --> 160 \n",
    "data.train_mask[:160] = True\n",
    "data.val_mask = torch.zeros([data.num_nodes,], dtype=torch.bool)\n",
    "data.val_mask[160:660] = True\n",
    "data.test_mask = torch.zeros([data.num_nodes,], dtype=torch.bool)\n",
    "data.test_mask[660:1660] = True\n",
    "\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cbbcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Sequential, GATConv, GCNConv\n",
    "from torch.nn import ELU, Dropout, ReLU\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, config):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.num_layers = config['depth']\n",
    "        self.act = config['activation_func']\n",
    "        self.dropout = 0.6\n",
    "        \n",
    "        self.convs = ModuleList()\n",
    "        self.convs.append(\n",
    "            GATConv(in_channels, \n",
    "                    8 if self.num_layers > 1 else out_channels, \n",
    "                    heads=config['heads'], \n",
    "                    dropout=self.dropout\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        for i in range(1, self.num_layers):\n",
    "            layer = None\n",
    "            if i == self.num_layers - 1:\n",
    "                # last layer\n",
    "                layer = GATConv(config['heads'] * 8,  out_channels, heads=1, dropout=self.dropout)\n",
    "            else:\n",
    "                layer = GATConv(config['heads'] * 8,  8, heads=config['heads'], dropout=self.dropout)\n",
    "                \n",
    "            self.convs.append(layer)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            if self.act is not None:\n",
    "                x = self.act(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            \n",
    "        return F.log_softmax(x, dim= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_stats(param_dict, train_acc, valid_acc, test_acc, filename):\n",
    "    global df \n",
    "    \n",
    "    df = df.append({\n",
    "                'depth': param_dict['depth'], \n",
    "                \"heads\": param_dict['heads'], \n",
    "                \"epochs\": param_dict['epochs'], \n",
    "                \"activation_func\": param_dict['activation_func'], \n",
    "                \"final_train_score\": train_acc, \n",
    "                \"valid_score\": valid_acc, \n",
    "                \"test_score\": test_acc\n",
    "    }, ignore_index=True)\n",
    "    df.to_csv(\"./grid_search_\" + filename + \".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf4e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np \n",
    "\n",
    "def grid_search(parameters, filename):\n",
    "    # Convertion from dict to product of dicts\n",
    "    \n",
    "    keys, values = zip(*parameters.items())\n",
    "    for prod in product(*values):\n",
    "        param_dict = dict(zip(keys, prod))\n",
    "        print(param_dict)\n",
    "        model = Net(\n",
    "            dataset.num_features,\n",
    "            dataset.num_classes,\n",
    "            param_dict\n",
    "        ).to(device)\n",
    "\n",
    "        optim = torch.optim.Adam(\n",
    "            model.parameters(), \n",
    "            lr=0.01, \n",
    "            weight_decay=0\n",
    "        )\n",
    "        \n",
    "        avg = np.empty([1,])\n",
    "        max_val = 0\n",
    "        early_stop_cnt = 0\n",
    "        train_acc = val_acc = test_acc = 0\n",
    "        for epoch in range(param_dict['epochs']):\n",
    "            # train\n",
    "            model.train()\n",
    "            optim.zero_grad()\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            # valid\n",
    "            accs = []\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                out = model(data.x, data.edge_index)\n",
    "                for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
    "                    acc = float((out[mask].argmax(-1) == data.y[mask]).sum() / mask.sum())\n",
    "                    accs.append(acc)\n",
    "            \n",
    "            \n",
    "            train_acc, val_acc, test_acc = accs\n",
    "            \n",
    "        print(train_acc, val_acc, test_acc)\n",
    "        log_stats(param_dict, train_acc, val_acc, test_acc, filename)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## grid search for amazon photos\n",
    "grid_search(hyper_parameters, \"photos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load datset\n",
    "dataset = 'Computers'\n",
    "path = os.path.join('data', dataset)\n",
    "dataset = Amazon(path, dataset, transform=T.NormalizeFeatures())\n",
    "\n",
    "## seeds\n",
    "torch.manual_seed(0)\n",
    "\n",
    "## add train / valid / test masks\n",
    "dataset.shuffle()\n",
    "data = dataset[0]\n",
    "data.train_mask = torch.zeros([data.num_nodes,], dtype=torch.bool)\n",
    "\n",
    "print(dataset.num_classes) # 10\n",
    "# 10 * 20 --> 200\n",
    "data.train_mask[:200] = True\n",
    "data.val_mask = torch.zeros([data.num_nodes,], dtype=torch.bool)\n",
    "data.val_mask[200:700] = True\n",
    "data.test_mask = torch.zeros([data.num_nodes,], dtype=torch.bool)\n",
    "data.test_mask[700:1700] = True\n",
    "\n",
    "data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0df1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_search(hyper_parameters, \"computers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3685818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669bd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
